\documentclass[10pt,english]{article}
\usepackage{mieic-abstracts}
\usepackage[english]{babel}
\usepackage[hidelinks]{hyperref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Automatic C/C++ source-code analysis and normalization}

\author{João Nuno Carvalho de Matos}
\email{me@joaonmatos.com}
\supervisor{Prof. João Bispo}
% \cosupervisor{Richard Feynman, PhD}

\abstract{Modern compiled software, written in languages such as C and C++, relies on complex compiler infrastructure that transforms programs in ways that improve their non-functional characteristics. However, developing new transformations and improving existing ones can be challenging to researchers and engineers. Often, transformations are conceived in terms of the high-level language, but must be implemented by transforming a lower-level intermediate representation (IR) or by modifying the compiler itself, which may not be feasible, for technical or legal reasons.
Source-to-source compilers make it possible to directly analyze and transform the original source, making transformations portable across different compilers. This approach allows transformations to be composed upstream of the compilation toolchain, allowing rapid research and prototyping of source code transformations, and its use has been proposed as a solution for implementing program transformations whenever it would prove to be infeasible or impractical to do so at the compiler level. One such tool is Clava, which embeds a scriptable Javascript environment and provides access to the Abstract Syntax Trees of C and C++ programs, allowing the source code to be queried and manipulated.
However, this approach has the drawback of exposing the researcher to the full breadth of the source language, which is often more extensive and complex than the IRs used in traditional compilers. Because of that complexity, it is hard to perform complete analyses that can account for all edge cases in the language. On the other hand, those constructs, such as loops or structures, can be useful to encode properties that are not made explicit in lower-level representations.
In this work, we propose a solution to tame the complexity of the source language and make source-to-source compilers an ergonomic platform for program optimization work, by dividing the transformations into two distinct steps. First, we define a simpler subset of the language that can encode the programs with fewer primitives, and implement a set of transformations, termed normalizations, to transform the input programs into equivalent programs expressed in that subset. Afterwards, we implement a function inlining transformation as a case study, showing how the assumptions afforded by using a simpler language subset allow us to successfully apply the transformation to codes that would otherwise not be able to be transformed.
We validate our experiment and evaluate our work by comparing the application of optimizations with and without normalization, in terms of the number of transformation cases successfully applied and the performance of the resulting programs, and test the composability of several transformations. On the one hand, the inlining transformations we tested were able to take advantage of the normalized language, regardless of whether they were developed with a normalized program in mind. Our performance testing also suggests that, in general, source-to-source compilation is a good technique to apply optimizations when using less developed compilers. On the other hand, we observed challenges when composing our transformations with existing source-code transformations, which expected  primitives that were not kept in the subset, such as for loops.}

\keywords{Source-to-source compilers. Source-code optimization. Source-code normalization}

\classification{
\begin{itemize}
\item Software and its engineering~$\rightarrow$~Software notations and tools~$\rightarrow$~Compilers
\end{itemize}
}

\begin{document}
\maketitle
\end{document} 