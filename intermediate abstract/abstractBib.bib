@article{Bispo2020,
   abstract = {This article presents Clava, a Clang-based source-to-source compiler, that accepts scripts written in LARA, a JavaScript-based DSL with special constructs for code queries, analysis and transformations. Clava improves Clang's source-to-source capabilities by providing a more convenient and flexible way to analyze, transform and generate C/C++ code, and provides support for building strategies that capture run-time behavior. We present the Clava framework, its main capabilities, and how it can been used. Furthermore, we show that Clava is sufficiently robust to analyze, instrument and test a set of large C/C++ application codes, such as GCC.},
   author = {João Bispo and João M.P. Cardoso},
   doi = {10.1016/J.SOFTX.2020.100565},
   issn = {2352-7110},
   journal = {SoftwareX},
   keywords = {C/C++,Compilers,LARA,Source-to-source},
   month = {7},
   pages = {100565},
   publisher = {Elsevier},
   title = {Clava: C/C++ source-to-source compilation using LARA},
   volume = {12},
   year = {2020},
}
@article{Bae2013,
   abstract = {This paper provides an overview and an evaluation of the Cetus source-to-source compiler infrastructure. The original goal of the Cetus project was to create an easy-to-use compiler for research in automatic parallelization of C programs. In meantime, Cetus has been used for many additional program transformation tasks. It serves as a compiler infrastructure for many projects in the US and internationally. Recently, Cetus has been supported by the National Science Foundation to build a community resource. The compiler has gone through several iterations of benchmark studies and implementations of those techniques that could improve the parallel performance of these programs. These efforts have resulted in a system that favorably compares with state-of-the-art parallelizers, such as Intel's ICC. A key limitation of advanced optimizing compilers is their lack of runtime information, such as the program input data. We will discuss and evaluate several techniques that support dynamic optimization decisions. Finally, as there is an extensive body of proposed compiler analyses and transformations for parallelization, the question of the importance of the techniques arises. This paper evaluates the impact of the individual Cetus techniques on overall program performance.},
   author = {Hansang Bae and Dheya Mustafa and Jae-Woo Lee and Hao Lin and Chirag Dave and Rudolf Eigenmann and Samuel P Midkiff and H Bae and D Mustafa and J-w Lee and H Lin and R Eigenmann and S P Midkiff and C Dave},
   doi = {10.1007/s10766-012-0211-z},
   journal = {Int J Parallel Prog},
   keywords = {Automatic parallelization ·,Compiler infrastructure ·,Performance,Source-to-source translation ·},
   pages = {753-767},
   title = {The Cetus Source-to-Source Compiler Infrastructure: Overview and Evaluation},
   volume = {41},
   year = {2013},
}
@article{Arabnejad2018,
   abstract = {Automatic parallelization of sequential code has become increasingly relevant in multicore programming. In particular, loop paral-lelization continues to be a promising optimization technique for scientiï¿¿c applications, and can provide considerable speedups for program execution. Furthermore, if we can verify that there are no true data dependencies between loop iterations, they can be easily parallelized. This paper describes Clava AutoPar, a library for the Clava weaver that performs automatic and symbolic parallelization of C code. The library is composed of two main parts, parallel loop detection and source-to-source code parallelization. The system is entirely automatic and attempts to statically detect parallel loops for a given input program, without any user intervention or proï¿¿l-ing information. We obtained a geometric mean speedup of 1.5 for a set of programs from the C version of the NAS benchmark, and experimental results suggest that the performance obtained with Clava AutoPar is comparable or better than other similar research and commercial tools.},
   author = {Hamid Arabnejad and João Bispo and Jorge G Barbosa and João M P Cardoso},
   city = {New York, New York, USA},
   doi = {10.1145/3183767},
   isbn = {9781450364447},
   journal = {Proceedings of the 9th Workshop and 7th Workshop on Parallel Programming and RunTime Management Techniques for Manycore Architectures and Design Tools and Architectures for Multicore Embedded Computing Platforms  - PARMA-DITAM '18},
   keywords = {Automatic parallelization,OpenMP,Parallel Programming,source-to-source Compilation},
   publisher = {ACM Press},
   title = {AutoPar-Clava: An Automatic Parallelization source-to-source tool for C code applications-Clava: An Automatic Parallelization source-to-source tool for C code applications. In PARMA-DITAM '18: 9th Workshop on Parallel Pro-gramming and RunTime Management Techniques for Manycore Architectures and 7th Workshop on Design Tools and Architectures for Multicore Embedded},
   volume = {18},
   url = {https://doi.org/10.1145/3183767.3183770},
   year = {2018},
}
@article{Lattner2004,
   abstract = {This paper describes LLVM (Low Level Virtual Machine), a compiler framework designed to support transparent, life-long program analysis and transformation for arbitrary programs, by providing high-level information to compiler transformations at compile-time, link-time, run-time, and in idle time between runs. LLVM defines a common, low-level code representation in Static Single Assignment (SSA) form, with several novel features: a simple, language-independent type-system that exposes the primitives commonly used to implement high-level language features; an instruction for typed address arithmetic; and a simple mechanism that can be used to implement the exception handling features of high-level languages (and setjmp/longjmp in C) uniformly and efficiently. The LLVM compiler framework and code representation together provide a combination of key capabilities that are important for practical, lifelong analysis and transformation of programs. To our knowledge, no existing compilation approach provides all these capabilities. We describe the design of the LLVM representation and compiler framework, and evaluate the design in three ways: (a) the size and effectiveness of the representation, including the type information it provides; (b) compiler performance for several interprocedural problems; and (c) illustrative examples of the benefits LLVM provides for several challenging compiler problems.},
   author = {Chris Lattner and Vikram Adve},
   doi = {10.1109/CGO.2004.1281665},
   isbn = {0769521029},
   journal = {International Symposium on Code Generation and Optimization, CGO},
   pages = {75-86},
   title = {LLVM: A compilation framework for lifelong program analysis & transformation},
   year = {2004},
}
